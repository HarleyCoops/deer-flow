# Application Settings
DEBUG=True
APP_ENV=development

# docker build args
NEXT_PUBLIC_API_URL="http://localhost:8000/api"

# Search Engine, Supported values: tavily (recommended), duckduckgo, brave_search, arxiv
SEARCH_API=tavily

TAVILY_API_KEY=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 
JINA_API_KEY=jina_118c4e048e584f7aab7bdfd7f219fafeKZxigDnP5YT2evrlsPydnAxNQqNQ



# Optional, volcengine TTS for generating podcast
VOLCENGINE_TTS_APPID=xxx
VOLCENGINE_TTS_ACCESS_TOKEN=xxx
# VOLCENGINE_TTS_CLUSTER=volcano_tts # Optional, default is volcano_tts
# VOLCENGINE_TTS_VOICE_TYPE=BV700_V2_streaming # Optional, default is BV700_V2_streaming

# Option, for langsmith tracing and monitoring
# LANGSMITH_TRACING=true
# LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
# LANGSMITH_API_KEY="xxx"
# LANGSMITH_PROJECT="xxx"

# [!NOTE]
# For model settings and other configurations, please refer to `docs/configuration_guide.md`
# Add your LLM/API keys and model settings below as needed for conf.yaml
# Example (uncomment and fill in):
# OPENAI_API_KEY=your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here
# LLAMA_API_BASE_URL=https://your-llama-endpoint
# LLAMA_API_KEY=your_llama_key_here
#
# See docs/configuration_guide.md for more options and details.
